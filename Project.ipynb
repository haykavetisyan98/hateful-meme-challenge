{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNmqGIkRhenY",
        "outputId": "17d52911-946f-4797-84c0-c5b74760b936"
      },
      "source": [
        "pip install tensorflow==2.4.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==2.4.0 in /usr/local/lib/python3.7/dist-packages (2.4.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (0.3.3)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.15.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.19.3)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (2.4.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.1.2)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (2.4.1)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (3.3.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (3.7.4.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (3.12.4)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.12.1)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.32.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.12)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (2.10.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (0.12.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (0.36.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (3.3.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (0.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (56.0.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (1.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (1.28.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.0) (3.10.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.0) (1.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (1.24.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (4.2.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.0) (3.4.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.0) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (0.4.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuCe8yYChjWR",
        "outputId": "9eae225f-6f2b-491f-b1e0-8628c3231517"
      },
      "source": [
        "pip install keras==2.4.3 numpy==1.19.3 pillow==7.0.0 scipy==1.4.1 h5py==2.10.0 matplotlib==3.3.2 opencv-python keras-resnet==0.2.0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras==2.4.3 in /usr/local/lib/python3.7/dist-packages (2.4.3)\n",
            "Requirement already satisfied: numpy==1.19.3 in /usr/local/lib/python3.7/dist-packages (1.19.3)\n",
            "Requirement already satisfied: pillow==7.0.0 in /usr/local/lib/python3.7/dist-packages (7.0.0)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (1.4.1)\n",
            "Requirement already satisfied: h5py==2.10.0 in /usr/local/lib/python3.7/dist-packages (2.10.0)\n",
            "Requirement already satisfied: matplotlib==3.3.2 in /usr/local/lib/python3.7/dist-packages (3.3.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: keras-resnet==0.2.0 in /usr/local/lib/python3.7/dist-packages (0.2.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.4.3) (3.13)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.15.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.2) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.2) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.2) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2020.06.20 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.2) (2020.12.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.2) (1.3.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQ_aQi-yhmpR",
        "outputId": "283a0967-691b-4146-fbce-db2891d9744f"
      },
      "source": [
        "pip install imageai --upgrade"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: imageai in /usr/local/lib/python3.7/dist-packages (2.1.6)\n",
            "Requirement already satisfied, skipping upgrade: keras==2.4.3 in /usr/local/lib/python3.7/dist-packages (from imageai) (2.4.3)\n",
            "Requirement already satisfied, skipping upgrade: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from imageai) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: h5py==2.10.0 in /usr/local/lib/python3.7/dist-packages (from imageai) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: opencv-python in /usr/local/lib/python3.7/dist-packages (from imageai) (4.1.2.30)\n",
            "Requirement already satisfied, skipping upgrade: keras-resnet==0.2.0 in /usr/local/lib/python3.7/dist-packages (from imageai) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy==1.19.3 in /usr/local/lib/python3.7/dist-packages (from imageai) (1.19.3)\n",
            "Requirement already satisfied, skipping upgrade: pillow==7.0.0 in /usr/local/lib/python3.7/dist-packages (from imageai) (7.0.0)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib==3.3.2 in /usr/local/lib/python3.7/dist-packages (from imageai) (3.3.2)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.4.3->imageai) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0->imageai) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2020.06.20 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.2->imageai) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.2->imageai) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.2->imageai) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.2->imageai) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.2->imageai) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWKHUKuThpLg",
        "outputId": "0f3ea748-7266-45a6-957b-cd5454afb481"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjhuDhA-kH7q"
      },
      "source": [
        "!pip install jsonlines"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kw2XoYdFi60b"
      },
      "source": [
        "%cd /content/drive/My Drive/Colab Notebooks/\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2TsbhznkNLq"
      },
      "source": [
        "import json\n",
        "import jsonlines\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xl_dtHdUkQUj"
      },
      "source": [
        "#!unzip '/content/drive/My Drive/Colab Notebooks/aca2021-meme-analysis-challenge.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hp4HiXHUkrPb"
      },
      "source": [
        "import json\n",
        "import jsonlines\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zegvHeu4lxwG"
      },
      "source": [
        "with jsonlines.open('train.jsonl') as reader:\n",
        "    data = pd.DataFrame(reader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RIauTDlmJ_b"
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwz08P9ioDe4"
      },
      "source": [
        "import os\n",
        "directory = '/content/drive/My Drive/Colab Notebooks/img'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1zpKtRnhjZi"
      },
      "source": [
        "from imageai.Detection import ObjectDetection\n",
        "import os\n",
        "\n",
        "execution_path = os.getcwd()\n",
        "\n",
        "detector = ObjectDetection()\n",
        "detector.setModelTypeAsRetinaNet()\n",
        "\n",
        "detector.setModelPath( os.path.join(execution_path , \"/content/drive/My Drive/Colab Notebooks/resnet50_coco_best_v2.1.0.h5\"))\n",
        "detector.loadModel()\n",
        "\n",
        "object_list_tr = []\n",
        "\n",
        "a = 1\n",
        "\n",
        "for rindex, row in data.iterrows():\n",
        "    detections = detector.detectObjectsFromImage(input_image=os.path.join(execution_path , \"/content/drive/My Drive/Colab Notebooks/{}\".format(row['img'])), output_image_path=os.path.join(execution_path , \"/content/drive/My Drive/Colab Notebooks/kk.png\"))\n",
        "\n",
        "    text = ' '\n",
        "\n",
        "    for eachObject in detections:\n",
        "        \n",
        "        text = text + ' '+ eachObject[\"name\"]\n",
        "    object_list_tr.append(text) \n",
        "    row['text'] = row['text']+text\n",
        "    a += 1\n",
        "    print(a)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0LE6dFmOE7W"
      },
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "\n",
        "data.to_csv('/content/drive/My Drive/Colab Notebooks/tr.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqll6y9PS2Ku"
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIS7oWoMM1P0"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "au81pqHHmiYG"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['text'], data['label'], test_size = 0.2, random_state = 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uS68bnTmL11"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfzmtLfdmPIr"
      },
      "source": [
        "from transformers import TFDistilBertModel, DistilBertConfig\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xz3NAsD3mRo2"
      },
      "source": [
        "from transformers import DistilBertTokenizer\n",
        "distil_bert = 'distilbert-base-uncased' # Pick any desired pre-trained model\n",
        "\n",
        "# Defining DistilBERT tokonizer\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(distil_bert, do_lower_case=True, add_special_tokens=True,\n",
        "                                                max_length=128, pad_to_max_length=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrHnm6jGmUlT"
      },
      "source": [
        "def tokenize(sentences, tokenizer):\n",
        "    input_ids, input_masks, input_segments = [],[],[]\n",
        "    for sentence in tqdm(sentences):\n",
        "        inputs = tokenizer.encode_plus(sentence, add_special_tokens=True, max_length=128, pad_to_max_length=True, \n",
        "                                             return_attention_mask=True, return_token_type_ids=True)\n",
        "        input_ids.append(inputs['input_ids'])\n",
        "        input_masks.append(inputs['attention_mask'])\n",
        "        input_segments.append(inputs['token_type_ids'])        \n",
        "        \n",
        "    return np.asarray(input_ids, dtype='int32'), np.asarray(input_masks, dtype='int32'), np.asarray(input_segments, dtype='int32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgxzHZa5mW28"
      },
      "source": [
        "input_id, input_mask, _ = tokenize(X_train, tokenizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_7VhDMpmYbj"
      },
      "source": [
        "input_id_all, input_mask_all, _ = tokenize(data[\"text\"], tokenizer)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2p-YN7-mlNi"
      },
      "source": [
        "distil_bert = 'distilbert-base-uncased'\n",
        "\n",
        "config = DistilBertConfig(dropout=0.2, attention_dropout=0.2)\n",
        "config.output_hidden_states = False\n",
        "transformer_model = TFDistilBertModel.from_pretrained(distil_bert, config = config)\n",
        "\n",
        "input_ids_in = tf.keras.layers.Input(shape=(128,), name='input_token', dtype='int32')\n",
        "input_masks_in = tf.keras.layers.Input(shape=(128,), name='masked_token', dtype='int32') \n",
        "\n",
        "embedding_layer = transformer_model(input_ids_in, attention_mask=input_masks_in)[0]\n",
        "X = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(50, return_sequences=True, dropout=0.2, recurrent_dropout=0.2))(embedding_layer)\n",
        "X = tf.keras.layers.Flatten()(X)\n",
        "X = tf.keras.layers.Dropout(0.25)(X)\n",
        "X = tf.keras.layers.Dense(150, activation='relu')(X)\n",
        "X = tf.keras.layers.Dropout(0.25)(X)\n",
        "X = tf.keras.layers.Dense(50, activation='relu')(X)\n",
        "X = tf.keras.layers.Dropout(0.5)(X)\n",
        "X = tf.keras.layers.Dense(1, activation='sigmoid')(X)\n",
        "model = tf.keras.Model(inputs=[input_ids_in, input_masks_in], outputs = X)\n",
        "\n",
        "for layer in model.layers[:3]:\n",
        "  layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbcDASukmsbz"
      },
      "source": [
        "N_EPOCHS = 8\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate= 2.5e-3)\n",
        "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy', tf.keras.metrics.AUC()])\n",
        "\n",
        "model.fit([input_id, input_mask], y_train, batch_size=BATCH_SIZE, epochs=N_EPOCHS, validation_split = 0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhEfYdNbmu-6"
      },
      "source": [
        "input_id_test, input_mask_test, _ = tokenize(X_test, tokenizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SnmqSvqmwpC"
      },
      "source": [
        "y_pred = model.predict([input_id_test, input_mask_test])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLRzB7uimx67"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "roc_auc_score(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6DozkHomzHj"
      },
      "source": [
        "with jsonlines.open('/content/drive/My Drive/Colab Notebooks/test.jsonl') as reader:\n",
        "    data_test = pd.DataFrame(reader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtdRpt-CTb0H"
      },
      "source": [
        "data_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJSWykwSV7u1"
      },
      "source": [
        "from imageai.Detection import ObjectDetection\n",
        "import os\n",
        "\n",
        "execution_path = os.getcwd()\n",
        "\n",
        "detector = ObjectDetection()\n",
        "detector.setModelTypeAsRetinaNet()\n",
        "\n",
        "detector.setModelPath( os.path.join(execution_path , \"/content/drive/My Drive/Colab Notebooks/resnet50_coco_best_v2.1.0.h5\"))\n",
        "detector.loadModel()\n",
        "\n",
        "object_list_ts = []\n",
        "\n",
        "a = 1\n",
        "\n",
        "for rindex, row in data_test.iterrows():\n",
        "    detections = detector.detectObjectsFromImage(input_image=os.path.join(execution_path , \"/content/drive/My Drive/Colab Notebooks/{}\".format(row['img'])), output_image_path=os.path.join(execution_path , \"/content/drive/My Drive/Colab Notebooks/kk.png\"))\n",
        "\n",
        "    text = ' '\n",
        "\n",
        "    for eachObject in detections:\n",
        "        \n",
        "        text = text + ' '+ eachObject[\"name\"] \n",
        "    object_list_ts.append(text)\n",
        "    row['text'] = row['text']+text\n",
        "    a += 1\n",
        "    print(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wT1LA6koWAyu"
      },
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "\n",
        "data_test.to_csv('/content/drive/My Drive/Colab Notebooks/ts.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhZY9d5CTqLX"
      },
      "source": [
        "input_id_test, input_mask_test, _ = tokenize(data_test['text'], tokenizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFDa9BRITsbH"
      },
      "source": [
        "y_pred = model.predict([input_id_test, input_mask_test])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrcQMzUJT8Zk"
      },
      "source": [
        "Submission = pd.DataFrame()\n",
        "Submission['id'] = data_test['id']\n",
        "Submission['label'] = y_pred\n",
        "Submission.to_csv(\"/content/drive/My Drive/Colab Notebooks/res_all_data_5_32_0.2.csv\",index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}